{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基本的な概念\n",
    "\n",
    "線形判別分析は、データをクラスに分類するための手法です。複数のクラスが存在するデータセットがあり、新しいデータがどのクラスに属するかを予測するために使われます。\n",
    "\n",
    "### 行列を使った説明\n",
    "\n",
    "1. **データセットの準備**:\n",
    "   各データ点は特徴量ベクトルで表されます。例えば、特徴量が2つ（$x_1$, $x_2$）の場合、データ点は $(x_1, x_2)$ という形になります。\n",
    "\n",
    "2. **クラスごとの平均ベクトル**:\n",
    "   各クラスに対して、そのクラスに属するデータ点の平均ベクトルを計算します。クラス $k$ の平均ベクトル $\\mathbf{\\mu}_k$ は次のように計算されます：\n",
    "   $$\n",
    "   \\mathbf{\\mu}_k = \\frac{1}{N_k} \\sum_{i \\in C_k} \\mathbf{x}_i\n",
    "   $$\n",
    "   ここで、$N_k$ はクラス $k$ のデータ点の数、$C_k$ はクラス $k$ に属するデータ点の集合です。\n",
    "\n",
    "3. **クラス内散布行列**:\n",
    "   各クラス内でのデータのばらつきを表す行列です。クラス $k$ のクラス内散布行列 $\\mathbf{S}_k$ は次のように計算されます：\n",
    "   $$\n",
    "   \\mathbf{S}_k = \\sum_{i \\in C_k} (\\mathbf{x}_i - \\mathbf{\\mu}_k)(\\mathbf{x}_i - \\mathbf{\\mu}_k)^T\n",
    "   $$\n",
    "\n",
    "4. **全クラスのクラス内散布行列**:\n",
    "   全クラスのクラス内散布行列を合計して、全クラスのクラス内散布行列 $\\mathbf{S}_W$ を求めます：\n",
    "   $$\n",
    "   \\mathbf{S}_W = \\sum_{k=1}^{K} \\mathbf{S}_k\n",
    "   $$\n",
    "\n",
    "5. **クラス間散布行列**:\n",
    "   各クラスの平均ベクトルと全体の平均ベクトルとの差を考慮して、クラス間のばらつきを表す行列です。全体の平均ベクトル $\\mathbf{\\mu}$ は次のように計算されます：\n",
    "   $$\n",
    "   \\mathbf{\\mu} = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbf{x}_i\n",
    "   $$\n",
    "   クラス $k$ のクラス間散布行列 $\\mathbf{S}_B$ は次のように計算されます：\n",
    "   $$\n",
    "   \\mathbf{S}_B = \\sum_{k=1}^{K} N_k (\\mathbf{\\mu}_k - \\mathbf{\\mu})(\\mathbf{\\mu}_k - \\mathbf{\\mu})^T\n",
    "   $$\n",
    "\n",
    "6. **最適な判別基準の計算**:\n",
    "   LDA の目的は、クラス間のばらつきを最大化しながら、クラス内のばらつきを最小化するような線形変換を見つけることです。これを行うために、次の最適化問題を解きます：\n",
    "   $$\n",
    "   \\mathbf{w} = \\arg\\max_{\\mathbf{w}} \\frac{\\mathbf{w}^T \\mathbf{S}_B \\mathbf{w}}{\\mathbf{w}^T \\mathbf{S}_W \\mathbf{w}}\n",
    "   $$\n",
    "   この問題を解くことで、判別基準となるベクトル $\\mathbf{w}$ を得ます。このベクトルを使って、新しいデータを分類します。\n",
    "\n",
    "### 結論\n",
    "\n",
    "線形判別分析は、行列やベクトルの操作を使ってデータを分類する手法です。クラスごとの平均ベクトルや散布行列を計算し、クラス間のばらつきを最大化し、クラス内のばらつきを最小化するような線形変換を見つけます。行列の基本操作を理解することで、LDAの背後にある数学的な考え方がわかりやすくなります。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実際の例を挙げながら説明してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "わかりました。それでは、実際の花のデータを使って、線形判別分析のステップを具体的に説明します。ここでは、アイリスデータセット（有名な花のデータセット）を使います。このデータセットには、3種類のアイリスの花（Setosa、Versicolor、Virginica）がありますが、ここではSetosaとVersicolorの2種類に絞って説明します。\n",
    "\n",
    "### ステップ1: データの準備\n",
    "\n",
    "データセットには、各花のがく片（sepal）の長さと幅、花弁（petal）の長さと幅が含まれています。ここでは、がく片の長さと幅の2つの特徴量を使います。\n",
    "\n",
    "| 花の種類  | がく片の長さ (cm) | がく片の幅 (cm) |\n",
    "|-------|-------------|-------------|\n",
    "| Setosa | 5.1         | 3.5         |\n",
    "| Setosa | 4.9         | 3.0         |\n",
    "| ...   | ...         | ...         |\n",
    "| Versicolor | 7.0     | 3.2         |\n",
    "| Versicolor | 6.4     | 3.2         |\n",
    "| ...   | ...         | ...         |\n",
    "\n",
    "### ステップ2: 平均ベクトルの計算\n",
    "\n",
    "それぞれのクラス（花の種類）について、平均ベクトルを計算します。\n",
    "\n",
    "#### Setosaの平均ベクトル\n",
    "$$\n",
    "\\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} \\mu_{Setosa, sepal\\_length} \\\\ \\mu_{Setosa, sepal\\_width} \\end{pmatrix} = \\begin{pmatrix} 5.0 \\\\ 3.4 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "#### Versicolorの平均ベクトル\n",
    "$$\n",
    "\\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} \\mu_{Versicolor, sepal\\_length} \\\\ \\mu_{Versicolor, sepal\\_width} \\end{pmatrix} = \\begin{pmatrix} 5.9 \\\\ 2.8 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### ステップ3: クラス内ばらつき行列の計算\n",
    "\n",
    "各クラス内のデータのばらつきを行列で表します。\n",
    "\n",
    "#### Setosaのクラス内ばらつき行列\n",
    "$$\n",
    "\\mathbf{S}_{\\text{Setosa}} = \\sum_{i=1}^{N_{Setosa}} (\\mathbf{x}_i - \\mathbf{\\mu}_{\\text{Setosa}})(\\mathbf{x}_i - \\mathbf{\\mu}_{\\text{Setosa}})^T\n",
    "$$\n",
    "\n",
    "#### Versicolorのクラス内ばらつき行列\n",
    "$$\n",
    "\\mathbf{S}_{\\text{Versicolor}} = \\sum_{i=1}^{N_{Versicolor}} (\\mathbf{x}_i - \\mathbf{\\mu}_{\\text{Versicolor}})(\\mathbf{x}_i - \\mathbf{\\mu}_{\\text{Versicolor}})^T\n",
    "$$\n",
    "\n",
    "### ステップ4: 全体のクラス内ばらつき行列の計算\n",
    "\n",
    "全体のクラス内ばらつき行列は、それぞれのクラス内ばらつき行列の合計です。\n",
    "$$\n",
    "\\mathbf{S}_W = \\mathbf{S}_{\\text{Setosa}} + \\mathbf{S}_{\\text{Versicolor}}\n",
    "$$\n",
    "\n",
    "### ステップ5: クラス間ばらつき行列の計算\n",
    "\n",
    "全体の平均ベクトルを計算し、クラス間のばらつきを行列で表します。\n",
    "\n",
    "#### 全体の平均ベクトル\n",
    "$$\n",
    "\\mathbf{\\mu} = \\frac{1}{N_{Setosa} + N_{Versicolor}} \\left( \\sum_{i=1}^{N_{Setosa}} \\mathbf{x}_i + \\sum_{i=1}^{N_{Versicolor}} \\mathbf{x}_i \\right)\n",
    "$$\n",
    "\n",
    "#### クラス間ばらつき行列\n",
    "$$\n",
    "\\mathbf{S}_B = N_{Setosa} (\\mathbf{\\mu}_{\\text{Setosa}} - \\mathbf{\\mu})(\\mathbf{\\mu}_{\\text{Setosa}} - \\mathbf{\\mu})^T + N_{Versicolor} (\\mathbf{\\mu}_{\\text{Versicolor}} - \\mathbf{\\mu})(\\mathbf{\\mu}_{\\text{Versicolor}} - \\mathbf{\\mu})^T\n",
    "$$\n",
    "\n",
    "### ステップ6: 最適な判別基準の計算\n",
    "\n",
    "LDAの目的は、次の最適化問題を解くことです：\n",
    "$$\n",
    "\\mathbf{w} = \\arg\\max_{\\mathbf{w}} \\frac{\\mathbf{w}^T \\mathbf{S}_B \\mathbf{w}}{\\mathbf{w}^T \\mathbf{S}_W \\mathbf{w}}\n",
    "$$\n",
    "\n",
    "この問題を解くことで、判別基準となるベクトル $\\mathbf{w}$ を得ます。このベクトルを使って、新しいデータを分類します。\n",
    "\n",
    "### まとめ\n",
    "\n",
    "具体的な花のデータを使って、LDAの各ステップを説明しました。行列の計算を通じて、データのばらつきや平均を求め、最適な分類線を見つけることで、新しいデータの分類が可能になります。これで、LDAの背後にある数学的な考え方と実際の計算の結びつきがわかりやすくなったと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ばらつき行列について理解できません。数字を出しながら説明してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ばらつき行列（散布行列）について、具体的な数値を使って説明します。アイリスデータセットのSetosaとVersicolorのデータを簡単な例として用います。\n",
    "\n",
    "### サンプルデータ\n",
    "SetosaとVersicolorの花のデータが以下のように与えられているとします。\n",
    "\n",
    "#### Setosa\n",
    "| がく片の長さ (cm) | がく片の幅 (cm) |\n",
    "|-------------|-------------|\n",
    "| 5.1         | 3.5         |\n",
    "| 4.9         | 3.0         |\n",
    "| 5.0         | 3.4         |\n",
    "\n",
    "#### Versicolor\n",
    "| がく片の長さ (cm) | がく片の幅 (cm) |\n",
    "|-------------|-------------|\n",
    "| 7.0         | 3.2         |\n",
    "| 6.4         | 3.2         |\n",
    "| 6.9         | 3.1         |\n",
    "\n",
    "### 平均ベクトルの計算\n",
    "\n",
    "まず、各クラスの平均ベクトルを計算します。\n",
    "\n",
    "#### Setosaの平均ベクトル\n",
    "$$\n",
    "\\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} \\mu_{1x} \\\\ \\mu_{1y} \\end{pmatrix} = \\begin{pmatrix} \\frac{5.1 + 4.9 + 5.0}{3} \\\\ \\frac{3.5 + 3.0 + 3.4}{3} \\end{pmatrix} = \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "#### Versicolorの平均ベクトル\n",
    "$$\n",
    "\\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} \\mu_{2x} \\\\ \\mu_{2y} \\end{pmatrix} = \\begin{pmatrix} \\frac{7.0 + 6.4 + 6.9}{3} \\\\ \\frac{3.2 + 3.2 + 3.1}{3} \\end{pmatrix} = \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### クラス内ばらつき行列の計算\n",
    "\n",
    "次に、各クラスのクラス内ばらつき行列を計算します。\n",
    "\n",
    "#### Setosaのクラス内ばらつき行列\n",
    "Setosaのデータ点の偏差ベクトルを求め、その外積をとります。\n",
    "\n",
    "1. データ点 (5.1, 3.5)\n",
    "$$\n",
    "\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} 5.1 \\\\ 3.5 \\end{pmatrix} - \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix} = \\begin{pmatrix} 0.1 \\\\ 0.2 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Setosa}})(\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Setosa}})^T = \\begin{pmatrix} 0.1 \\\\ 0.2 \\end{pmatrix} \\begin{pmatrix} 0.1 & 0.2 \\end{pmatrix} = \\begin{pmatrix} 0.01 & 0.02 \\\\ 0.02 & 0.04 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "2. データ点 (4.9, 3.0)\n",
    "$$\n",
    "\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} 4.9 \\\\ 3.0 \\end{pmatrix} - \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix} = \\begin{pmatrix} -0.1 \\\\ -0.3 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Setosa}})(\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Setosa}})^T = \\begin{pmatrix} -0.1 \\\\ -0.3 \\end{pmatrix} \\begin{pmatrix} -0.1 & -0.3 \\end{pmatrix} = \\begin{pmatrix} 0.01 & 0.03 \\\\ 0.03 & 0.09 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "3. データ点 (5.0, 3.4)\n",
    "$$\n",
    "\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} 5.0 \\\\ 3.4 \\end{pmatrix} - \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0.1 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Setosa}})(\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Setosa}})^T = \\begin{pmatrix} 0 \\\\ 0.1 \\end{pmatrix} \\begin{pmatrix} 0 & 0.1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0.01 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Setosaのクラス内ばらつき行列 $\\mathbf{S}_{\\text{Setosa}}$ はこれらの和です：\n",
    "$$\n",
    "\\mathbf{S}_{\\text{Setosa}} = \\begin{pmatrix} 0.01 & 0.02 \\\\ 0.02 & 0.04 \\end{pmatrix} + \\begin{pmatrix} 0.01 & 0.03 \\\\ 0.03 & 0.09 \\end{pmatrix} + \\begin{pmatrix} 0 & 0 \\\\ 0 & 0.01 \\end{pmatrix} = \\begin{pmatrix} 0.02 & 0.05 \\\\ 0.05 & 0.14 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "#### Versicolorのクラス内ばらつき行列\n",
    "同様にしてVersicolorのクラス内ばらつき行列を計算します。\n",
    "\n",
    "1. データ点 (7.0, 3.2)\n",
    "$$\n",
    "\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} 7.0 \\\\ 3.2 \\end{pmatrix} - \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix} = \\begin{pmatrix} 0.24 \\\\ 0.03 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Versicolor}})(\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Versicolor}})^T = \\begin{pmatrix} 0.24 \\\\ 0.03 \\end{pmatrix} \\begin{pmatrix} 0.24 & 0.03 \\end{pmatrix} = \\begin{pmatrix} 0.0576 & 0.0072 \\\\ 0.0072 & 0.0009 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "2. データ点 (6.4, 3.2)\n",
    "$$\n",
    "\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} 6.4 \\\\ 3.2 \\end{pmatrix} - \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix} = \\begin{pmatrix} -0.36 \\\\ 0.03 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Versicolor}})(\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Versicolor}})^T = \\begin{pmatrix} -0.36 \\\\ 0.03 \\end{pmatrix} \\begin{pmatrix} -0.36 & 0.03 \\end{pmatrix} = \\begin{pmatrix} 0.1296 & -0.0108 \\\\ -0.0108 & 0.0009 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "3. データ点 (6.9, 3.1)\n",
    "$$\n",
    "\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} 6.9 \\\\ 3.1 \\end{pmatrix} - \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix} = \\begin{pmatrix} 0.14 \\\\ -0.07 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Versicolor}})(\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Versicolor}})^T = \\begin{pmatrix} 0.14 \\\\ -0.07 \\end{pmatrix} \\begin{pmatrix} 0.14 & -0.07 \\end{pmatrix} = \\begin{pmatrix} 0.0196 & -0.0098 \\\\ -0.0098 & 0.0049 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Versicolorのクラス内ばらつき行列 $\\mathbf{S}_{\\text{Versicolor}}$ はこれらの和です：\n",
    "$$\n",
    "\\mathbf{S}_{\\text{Versicolor}} = \\begin{pmatrix} 0.0576 & 0.0072 \\\\ 0.0072 & 0.0009 \\end{pmatrix} + \\begin{pmatrix} 0.1296 & -0.0108 \\\\ -0.0108 & 0.0009 \\end{pmatrix} + \\begin{pmatrix} 0.0196 & -0.0098 \\\\ -0.0098 & 0.0049 \\end{pmatrix} = \\begin{pmatrix} 0.2068 & -0.0134 \\\\ -0.0134 & 0.0067 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### クラス内ばらつき行列の合計\n",
    "全体のクラス内ばらつき行列 $\\mathbf{S}_W$ は、SetosaとVersicolorのクラス内ばらつき行列の合計です：\n",
    "$$\n",
    "\\mathbf{S}_W = \\mathbf{S}_{\\text{Setosa}} + \\mathbf{S}_{\\text{Versicolor}} = \\begin{pmatrix} 0.02 & 0.05 \\\\ 0.05 & 0.14 \\end{pmatrix} + \\begin{pmatrix} 0.2068 & -0.0134 \\\\ -0.0134 & 0.0067 \\end{pmatrix} = \\begin{pmatrix} 0.2268 & 0.0366 \\\\ 0.0366 & 0.1467 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "このように、各クラスのデータ点のばらつきを計算し、行列として表現することで、データのばらつきを具体的に理解することができます。これがLDAにおけるばらつき行列の計算方法です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "了解しました。このステップは線形判別分析（LDA）の最も重要な部分で、データを最もよく分けるための最適な線を見つける部分です。以下に、この部分について詳しく説明します。\n",
    "\n",
    "### 目的\n",
    "\n",
    "LDAの目的は、データを異なるクラスにうまく分類するための最適な線（または平面）を見つけることです。この線は、クラス間のばらつきを最大化し、クラス内のばらつきを最小化するように選ばれます。\n",
    "\n",
    "### 数式の意味\n",
    "\n",
    "最適な線を見つけるために、以下の最適化問題を解きます：\n",
    "$$\n",
    "\\mathbf{w} = \\arg\\max_{\\mathbf{w}} \\frac{\\mathbf{w}^T \\mathbf{S}_B \\mathbf{w}}{\\mathbf{w}^T \\mathbf{S}_W \\mathbf{w}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数式の意味\n",
    "\n",
    "1. **$\\mathbf{w}$**:\n",
    "   - これは、データをプロジェクションするためのベクトルです。LDAでは、このベクトルを見つけることが目的です。\n",
    "\n",
    "2. **$\\mathbf{S}_B$**:\n",
    "   - クラス間ばらつき行列です。これは、各クラスの平均が全体の平均からどれだけ離れているかを示します。\n",
    "\n",
    "3. **$\\mathbf{S}_W$**:\n",
    "   - クラス内ばらつき行列です。これは、各クラス内のデータのばらつきを示します。\n",
    "\n",
    "4. **$\\mathbf{w}^T \\mathbf{S}_B \\mathbf{w}$**:\n",
    "   - これは、ベクトル $\\mathbf{w}$ によってプロジェクションされた後のクラス間のばらつきを表します。\n",
    "\n",
    "5. **$\\mathbf{w}^T \\mathbf{S}_W \\mathbf{w}$**:\n",
    "   - これは、ベクトル $\\mathbf{w}$ によってプロジェクションされた後のクラス内のばらつきを表します。\n",
    "\n",
    "### 最適化問題の意図\n",
    "\n",
    "最適化問題の意図は、クラス間のばらつきを最大化し、同時にクラス内のばらつきを最小化することです。数式で言うと、分子 $\\mathbf{w}^T \\mathbf{S}_B \\mathbf{w}$ を最大化し、分母 $\\mathbf{w}^T \\mathbf{S}_W \\mathbf{w}$ を最小化することです。これにより、異なるクラスがより明確に分離されるようになります。\n",
    "\n",
    "### 解法\n",
    "\n",
    "この最適化問題は、一般的に次の手順で解かれます。\n",
    "\n",
    "1. **一般化固有値問題の解法**:\n",
    "   - 次の一般化固有値問題を解きます：\n",
    "     $$\n",
    "     \\mathbf{S}_B \\mathbf{w} = \\lambda \\mathbf{S}_W \\mathbf{w}\n",
    "     $$\n",
    "   - ここで、$\\lambda$ は固有値、$\\mathbf{w}$ は対応する固有ベクトルです。\n",
    "\n",
    "2. **固有ベクトルの選択**:\n",
    "   - 固有値が最大となる固有ベクトル $\\mathbf{w}$ を選びます。このベクトルが最適なプロジェクション方向となります。\n",
    "\n",
    "### 結果の利用\n",
    "\n",
    "得られたベクトル $\\mathbf{w}$ を使って、データを新しい空間にプロジェクションします。具体的には、新しいデータ点 $\\mathbf{x}$ を $\\mathbf{w}$ に沿ってプロジェクションすることで、スカラー値 $\\mathbf{w}^T \\mathbf{x}$ を得ます。このスカラー値を使って、データがどのクラスに属するかを判断します。\n",
    "\n",
    "### まとめ\n",
    "\n",
    "この最適化問題を解くことで、データを異なるクラスにうまく分けるための最適な線（またはベクトル）$\\mathbf{w}$ を見つけます。このベクトルを使って、新しいデータを分類することができます。クラス間のばらつきを最大化し、クラス内のばらつきを最小化することで、LDAは分類性能を向上させます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# プロジェクションとは何ですか？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "プロジェクション（射影）とは、ある高次元空間の点をより低次元の空間に写し取る操作のことです。直感的に言うと、プロジェクションはデータの次元を減らすための方法です。\n",
    "\n",
    "### 具体例で説明\n",
    "\n",
    "例えば、3次元空間の点を2次元の平面にプロジェクトすることを考えてみましょう。\n",
    "\n",
    "#### 3次元の点\n",
    "3次元空間には $(x, y, z)$ という座標があります。\n",
    "\n",
    "#### 2次元へのプロジェクション\n",
    "この点を $z$ 軸に垂直な平面（例えば $xy$ 平面）にプロジェクトすると、$z$ の情報は失われ、点の座標は $(x, y)$ になります。これは、3次元の点を2次元に「写し取った」ことを意味します。\n",
    "\n",
    "### 線形判別分析（LDA）でのプロジェクション\n",
    "\n",
    "LDAにおいて、プロジェクションは次のように行われます：\n",
    "\n",
    "1. **高次元のデータ**：\n",
    "   元のデータは多次元（例えば、2次元、3次元、またはそれ以上）です。\n",
    "\n",
    "2. **ベクトル $\\mathbf{w}$ の決定**：\n",
    "   最適なプロジェクション方向（ベクトル $\\mathbf{w}$）を見つけます。このベクトルは、クラス間のばらつきを最大化し、クラス内のばらつきを最小化する方向です。\n",
    "\n",
    "3. **データのプロジェクション**：\n",
    "   各データ点 $\\mathbf{x}$ をベクトル $\\mathbf{w}$ にプロジェクトします。これは、スカラー値 $\\mathbf{w}^T \\mathbf{x}$ を計算することで行われます。このスカラー値は、元の高次元空間のデータ点を1次元の空間に写し取った値です。\n",
    "\n",
    "具体的には、データ点 $\\mathbf{x}$ をベクトル $\\mathbf{w}$ にプロジェクトすることで、新しい1次元の座標（スカラー値）を得ます：\n",
    "$$\n",
    "y = \\mathbf{w}^T \\mathbf{x}\n",
    "$$\n",
    "\n",
    "この結果、元の高次元データは1次元の空間に縮約されます。この1次元空間での値を使って、データのクラスを判別します。\n",
    "\n",
    "### まとめ\n",
    "\n",
    "プロジェクションとは、データを高次元空間から低次元空間に写し取る操作です。LDAでは、プロジェクションを使ってデータを低次元空間に縮約し、データのクラス間の分離を最大化することを目指します。これにより、データの次元が減少し、視覚化や解析が容易になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "5.1 & 3.5 \\\\\n",
    "4.9 & 3.0 \\\\\n",
    "5.0 & 3.4\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "7.0 & 3.2 \\\\\n",
    "6.4 & 3.2 \\\\\n",
    "6.9 & 3.1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "各クラスの平均ベクトルを計算します。\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} \\frac{5.1 + 4.9 + 5.0}{3} \\\\ \\frac{3.5 + 3.0 + 3.4}{3} \\end{pmatrix} = \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} \\frac{7.0 + 6.4 + 6.9}{3} \\\\ \\frac{3.2 + 3.2 + 3.1}{3} \\end{pmatrix} = \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "各クラス内のデータのばらつきを計算します。\n",
    "\n",
    "\n",
    "\n",
    "1. データ点 (5.1, 3.5)\n",
    "$$\n",
    "\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} 5.1 \\\\ 3.5 \\end{pmatrix} - \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix} = \\begin{pmatrix} 0.1 \\\\ 0.2 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Setosa}})(\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Setosa}})^T = \\begin{pmatrix} 0.1 \\\\ 0.2 \\end{pmatrix} \\begin{pmatrix} 0.1 & 0.2 \\end{pmatrix} = \\begin{pmatrix} 0.01 & 0.02 \\\\ 0.02 & 0.04 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "2. データ点 (4.9, 3.0)\n",
    "$$\n",
    "\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} 4.9 \\\\ 3.0 \\end{pmatrix} - \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix} = \\begin{pmatrix} -0.1 \\\\ -0.3 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Setosa}})(\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Setosa}})^T = \\begin{pmatrix} -0.1 \\\\ -0.3 \\end{pmatrix} \\begin{pmatrix} -0.1 & -0.3 \\end{pmatrix} = \\begin{pmatrix} 0.01 & 0.03 \\\\ 0.03 & 0.09 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "3. データ点 (5.0, 3.4)\n",
    "$$\n",
    "\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} 5.0 \\\\ 3.4 \\end{pmatrix} - \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0.1 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Setosa}})(\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Setosa}})^T = \\begin{pmatrix} 0 \\\\ 0.1 \\end{pmatrix} \\begin{pmatrix} 0 & 0.1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0.01 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Setosaのクラス内ばらつき行列 $\\mathbf{S}_{\\text{Setosa}}$ はこれらの和です：\n",
    "$$\n",
    "\\mathbf{S}_{\\text{Setosa}} = \\begin{pmatrix} 0.01 & 0.02 \\\\ 0.02 & 0.04 \\end{pmatrix} + \\begin{pmatrix} 0.01 & 0.03 \\\\ 0.03 & 0.09 \\end{pmatrix} + \\begin{pmatrix} 0 & 0 \\\\ 0 & 0.01 \\end{pmatrix} = \\begin{pmatrix} 0.02 & 0.05 \\\\ 0.05 & 0.14 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "1. データ点 (7.0, 3.2)\n",
    "$$\n",
    "\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} 7.0 \\\\ 3.2 \\end{pmatrix} - \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix} = \\begin{pmatrix} 0.24 \\\\ 0.03 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Versicolor}})(\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Versicolor}})^T = \\begin{pmatrix} 0.24 \\\\ 0.03 \\end{pmatrix} \\begin{pmatrix} 0.24 & 0.03 \\end{pmatrix} = \\begin{pmatrix} 0.0576 & 0.0072 \\\\ 0.0072 & 0.0009 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "2. データ点 (6.4, 3.2)\n",
    "$$\n",
    "\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} 6.4 \\\\ 3.2 \\end{pmatrix} - \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix} = \\begin{pmatrix} -0.36 \\\\ 0.03 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Versicolor}})(\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Versicolor}})^T = \\begin{pmatrix} -0.36 \\\\ 0.03 \\end{pmatrix} \\begin{pmatrix} -0.36 & 0.03 \\end{pmatrix} = \\begin{pmatrix} 0.1296 & -0.0108 \\\\ -0.0108 & 0.0009 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "3. データ点 (6.9, 3.1)\n",
    "$$\n",
    "\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} 6.9 \\\\ 3.1 \\end{pmatrix} - \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix} = \\begin{pmatrix} 0.14 \\\\ -0.07 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Versicolor}})(\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Versicolor}})^T = \\begin{pmatrix} 0.14 \\\\ -0.07 \\end{pmatrix} \\begin{pmatrix} 0.14 & -0.07 \\end{pmatrix} = \\begin{pmatrix} 0.0196 & -0.0098 \\\\ -0.0098 & 0.0049 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Versicolorのクラス内ばらつき行列 $\\mathbf{S}_{\\text{Versicolor}}$ はこれらの和です：\n",
    "$$\n",
    "\\mathbf{S}_{\\text{Versicolor}} = \\begin{pmatrix} 0.0576 & 0.0072 \\\\ 0.0072 & 0.0009 \\end{pmatrix} + \\begin{pmatrix} 0.1296 & -0.0108 \\\\ -0.0108 & 0.0009 \\end{pmatrix} + \\begin{pmatrix} 0.0196 & -0.0098 \\\\ -0.0098 & 0.0049 \\end{pmatrix} = \\begin{pmatrix} 0.2068 & -0.0134 \\\\ -0.0134 & 0.0067 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### クラス内ばらつき行列の合計\n",
    "\n",
    "全体のクラス内ばらつき行列 $\\mathbf{S}_W$ は、SetosaとVersicolorのクラス内ばらつき行列の合計です：\n",
    "$$\n",
    "\\mathbf{S}_W = \\mathbf{S}_{\\text{Setosa}} + \\mathbf{S}_{\\text{Versicolor}} = \\begin{pmatrix} 0.02 & 0.05 \\\\ 0.05 & 0.14 \\end{pmatrix} + \\begin{pmatrix} 0.2068 & -0.0134 \\\\ -0.0134 & 0.0067 \\end{pmatrix} = \\begin{pmatrix} 0.2268 & 0.0366 \\\\ 0.0366 & 0.1467 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### クラス間ばらつき行列の計算\n",
    "\n",
    "クラス間ばらつき行列は、クラスごとの平均ベクトルが全体の平均からどれだけ離れているかを示します。\n",
    "\n",
    "#### 全体の平均ベクトル\n",
    "$$\n",
    "\\mathbf{\\mu} = \\frac{1}{6} \\left( \\sum_{i=1}^{3} \\mathbf{x}_{\\text{Setosa},i} + \\sum_{i=1}^{3} \\mathbf{x}_{\\text{Versicolor},i} \\right) = \\begin{pmatrix} \\frac{5.1 + 4.9 + 5.0 + 7.0 + 6.4 + 6.9}{6} \\\\ \\frac{3.5 + 3.0 + 3.4 + 3.2 + 3.2 + 3.1}{6} \\end{pmatrix} = \\begin{pmatrix} 5.883 \\\\ 3.233 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "#### クラス間ばらつき行列\n",
    "$$\n",
    "\\mathbf{S}_B = 3 (\\mathbf{\\mu}_{\\text{Setosa}} - \\mathbf{\\mu})(\\mathbf{\\mu}_{\\text{Setosa}} - \\mathbf{\\mu})^T + 3 (\\mathbf{\\mu}_{\\text{Versicolor}} - \\mathbf{\\mu})(\\mathbf{\\mu}_{\\text{Versicolor}} - \\mathbf{\\mu})^T\n",
    "$$\n",
    "\n",
    "計算してみます：\n",
    "$$\n",
    "(\\mathbf{\\mu}_{\\text{Setosa}} - \\mathbf{\\mu}) = \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix} - \\begin{pmatrix} 5.883 \\\\ 3.233 \\end{pmatrix} = \\begin{pmatrix} -0.883 \\\\ 0.067 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{\\mu}_{\\text{Versicolor}} - \\mathbf{\\mu}) = \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix} - \\begin{pmatrix} 5.883 \\\\ 3.233 \\end{pmatrix} = \\begin{pmatrix} 0.877 \\\\ -0.063 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{\\mu}_{\\text{Setosa}} - \\mathbf{\\mu})(\\mathbf{\\mu}_{\\text{Setosa}} - \\mathbf{\\mu})^T = \\begin{pmatrix} -0.883 \\\\ 0.067 \\end{pmatrix} \\begin{pmatrix} -0.883 & 0.067 \\end{pmatrix} = \\begin{pmatrix} 0.779 & -0.059 \\\\ -0.059 & 0.004 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{\\mu}_{\\text{Versicolor}} - \\mathbf{\\mu})(\\mathbf{\\mu}_{\\text{Versicolor}} - \\mathbf{\\mu})^T = \\begin{pmatrix} 0.877 \\\\ -0.063 \\end{pmatrix} \\begin{pmatrix} 0.877 & -0.063 \\end{pmatrix} = \\begin{pmatrix} 0.769 & -0.055 \\\\ -0.055 & 0.004 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "これらの行列を足し合わせます：\n",
    "$$\n",
    "\\mathbf{S}_B = 3 \\begin{pmatrix} 0.779 & -0.059 \\\\ -0.059 & 0.004 \\end{pmatrix} + 3 \\begin{pmatrix} 0.769 & -0.055 \\\\ -0.055 & 0.004 \\end{pmatrix} = 3 \\begin{pmatrix} 1.548 & -0.114 \\\\ -0.114 & 0.008 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### プロジェクションの計算\n",
    "\n",
    "次に、クラス間ばらつき行列 $\\mathbf{S}_B$ とクラス内ばらつき行列 $\\mathbf{S}_W$ を用いて、最適なプロジェクションベクトル $\\mathbf{w}$ を計算します。\n",
    "\n",
    "一般化固有値問題を解きます：\n",
    "$$\n",
    "\\mathbf{S}_B \\mathbf{w} = \\lambda \\mathbf{S}_W \\mathbf{w}\n",
    "$$\n",
    "\n",
    "これにより、最適なプロジェクションベクトル $\\mathbf{w}$ を得ます。計算の具体的な解法には、線形代数の技法（固有値問題の解法）が必要ですが、ここでは数学的に最適なベクトル $\\mathbf{w}$ を得るために必要なステップを示しました。\n",
    "\n",
    "### まとめ\n",
    "\n",
    "この例では、具体的な数値を用いてクラス間ばらつき行列、クラス内ばらつき行列、そしてプロジェクションの計算を行いました。これにより、LDAの計算の流れと各ステップの意味が明確になることを期待します。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 線形判別分析の具体例\n",
    "\n",
    "簡単のため、2つのクラス（Setosa と Versicolor）のデータを2つの特徴量（がく片の長さと幅）で表現します。\n",
    "\n",
    "## データセット\n",
    "\n",
    "### Setosa\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "5.1 & 3.5 \\\\\n",
    "4.9 & 3.0 \\\\\n",
    "5.0 & 3.4\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### Versicolor\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "7.0 & 3.2 \\\\\n",
    "6.4 & 3.2 \\\\\n",
    "6.9 & 3.1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "## 平均ベクトルの計算\n",
    "\n",
    "各クラスの平均ベクトルを計算します。\n",
    "\n",
    "### Setosaの平均ベクトル\n",
    "$$\n",
    "\\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} \\frac{5.1 + 4.9 + 5.0}{3} \\\\ \\frac{3.5 + 3.0 + 3.4}{3} \\end{pmatrix} = \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### Versicolorの平均ベクトル\n",
    "$$\n",
    "\\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} \\frac{7.0 + 6.4 + 6.9}{3} \\\\ \\frac{3.2 + 3.2 + 3.1}{3} \\end{pmatrix} = \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5. , 3.3]), array([6.76666667, 3.16666667]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# データセット\n",
    "setosa = np.array([[5.1, 3.5], [4.9, 3.0], [5.0, 3.4]])\n",
    "versicolor = np.array([[7.0, 3.2], [6.4, 3.2], [6.9, 3.1]])\n",
    "\n",
    "# 平均ベクトルの計算\n",
    "mu_setosa = np.mean(setosa, axis=0)\n",
    "mu_versicolor = np.mean(versicolor, axis=0)\n",
    "mu_setosa, mu_versicolor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クラス内ばらつき行列の計算\n",
    "\n",
    "各クラス内のデータのばらつきを計算します。\n",
    "\n",
    "### Setosaのクラス内ばらつき行列\n",
    "\n",
    "1. データ点 (5.1, 3.5)\n",
    "$$\n",
    "\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} 5.1 \\\\ 3.5 \\end{pmatrix} - \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix} = \\begin{pmatrix} 0.1 \\\\ 0.2 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Setosa}})(\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Setosa}})^T = \\begin{pmatrix} 0.1 \\\\ 0.2 \\end{pmatrix} \\begin{pmatrix} 0.1 & 0.2 \\end{pmatrix} = \\begin{pmatrix} 0.01 & 0.02 \\\\ 0.02 & 0.04 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "2. データ点 (4.9, 3.0)\n",
    "$$\n",
    "\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} 4.9 \\\\ 3.0 \\end{pmatrix} - \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix} = \\begin{pmatrix} -0.1 \\\\ -0.3 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Setosa}})(\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Setosa}})^T = \\begin{pmatrix} -0.1 \\\\ -0.3 \\end{pmatrix} \\begin{pmatrix} -0.1 & -0.3 \\end{pmatrix} = \\begin{pmatrix} 0.01 & 0.03 \\\\ 0.03 & 0.09 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "3. データ点 (5.0, 3.4)\n",
    "$$\n",
    "\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} 5.0 \\\\ 3.4 \\end{pmatrix} - \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0.1 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Setosa}})(\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Setosa}})^T = \\begin{pmatrix} 0 \\\\ 0.1 \\end{pmatrix} \\begin{pmatrix} 0 & 0.1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0.01 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Setosaのクラス内ばらつき行列 $\\mathbf{S}_{\\text{Setosa}}$ はこれらの和です：\n",
    "$$\n",
    "\\mathbf{S}_{\\text{Setosa}} = \\begin{pmatrix} 0.01 & 0.02 \\\\ 0.02 & 0.04 \\end{pmatrix} + \\begin{pmatrix} 0.01 & 0.03 \\\\ 0.03 & 0.09 \\end{pmatrix} + \\begin{pmatrix} 0 & 0 \\\\ 0 & 0.01 \\end{pmatrix} = \\begin{pmatrix} 0.02 & 0.05 \\\\ 0.05 & 0.14 \\end{pmatrix}\n",
    "$$\n",
    "### Versicolorのクラス内ばらつき行列\n",
    "\n",
    "1. データ点 (7.0, 3.2)\n",
    "$$\n",
    "\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} 7.0 \\\\ 3.2 \\end{pmatrix} - \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix} = \\begin{pmatrix} 0.24 \\\\ 0.03 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Versicolor}})(\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Versicolor}})^T = \\begin{pmatrix} 0.24 \\\\ 0.03 \\end{pmatrix} \\begin{pmatrix} 0.24 & 0.03 \\end{pmatrix} = \\begin{pmatrix} 0.0576 & 0.0072 \\\\ 0.0072 & 0.0009 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "2. データ点 (6.4, 3.2)\n",
    "$$\n",
    "\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} 6.4 \\\\ 3.2 \\end{pmatrix} - \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix} = \\begin{pmatrix} -0.36 \\\\ 0.03 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Versicolor}})(\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Versicolor}})^T = \\begin{pmatrix} -0.36 \\\\ 0.03 \\end{pmatrix} \\begin{pmatrix} -0.36 & 0.03 \\end{pmatrix} = \\begin{pmatrix} 0.1296 & -0.0108 \\\\ -0.0108 & 0.0009 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "3. データ点 (6.9, 3.1)\n",
    "$$\n",
    "\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} 6.9 \\\\ 3.1 \\end{pmatrix} - \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix} = \\begin{pmatrix} 0.14 \\\\ -0.07 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Versicolor}})(\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Versicolor}})^T = \\begin{pmatrix} 0.14 \\\\ -0.07 \\end{pmatrix} \\begin{pmatrix} 0.14 & -0.07 \\end{pmatrix} = \\begin{pmatrix} 0.0196 & -0.0098 \\\\ -0.0098 & 0.0049 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Versicolorのクラス内ばらつき行列 $\\mathbf{S}_{\\text{Versicolor}}$ はこれらの和です：\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "0.0576 & 0.0072 \\\\\n",
    "0.0072 & 0.0009\n",
    "\\end{pmatrix} + \n",
    "\\begin{pmatrix}\n",
    "0.1296 & -0.0108 \\\\\n",
    "-0.0108 & 0.0009\n",
    "\\end{pmatrix} + \n",
    "\\begin{pmatrix}\n",
    "0.0196 & -0.0098 \\\\\n",
    "-0.0098 & 0.0049\n",
    "\\end{pmatrix} = \n",
    "\\begin{pmatrix}\n",
    "0.2068 & -0.0134 \\\\\n",
    "-0.0134 & 0.0067\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.02, 0.05],\n",
       "        [0.05, 0.14]]),\n",
       " array([[ 0.20666667, -0.01333333],\n",
       "        [-0.01333333,  0.00666667]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scatter_matrix(data, mean):\n",
    "    scatter = np.zeros((2, 2))\n",
    "    for x in data:\n",
    "        diff = (x - mean).reshape(2, 1)\n",
    "        scatter += diff @ diff.T\n",
    "    return scatter\n",
    "\n",
    "S_setosa = scatter_matrix(setosa, mu_setosa)\n",
    "S_versicolor = scatter_matrix(versicolor, mu_versicolor)\n",
    "S_setosa, S_versicolor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### クラス内ばらつき行列の合計\n",
    "\n",
    "全体のクラス内ばらつき行列 $\\mathbf{S}_W$ は、SetosaとVersicolorのクラス内ばらつき行列の合計です：\n",
    "$$\n",
    "\\mathbf{S}_W = \\mathbf{S}_{\\text{Setosa}} + \\mathbf{S}_{\\text{Versicolor}} = \n",
    "\\begin{pmatrix}\n",
    "0.02 & 0.05 \\\\\n",
    "0.05 & 0.14\n",
    "\\end{pmatrix} + \n",
    "\\begin{pmatrix}\n",
    "0.2068 & -0.0134 \\\\\n",
    "-0.0134 & 0.0067\n",
    "\\end{pmatrix} = \n",
    "\\begin{pmatrix}\n",
    "0.2268 & 0.0366 \\\\\n",
    "0.0366 & 0.1467\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22666667, 0.03666667],\n",
       "       [0.03666667, 0.14666667]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_W = S_setosa + S_versicolor\n",
    "S_W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全体の平均ベクトル\n",
    "\n",
    "$$\n",
    "\\mathbf{\\mu} = \\frac{1}{6} \\left( \\sum_{i=1}^{3} \\mathbf{x}_{\\text{Setosa},i} + \\sum_{i=1}^{3} \\mathbf{x}_{\\text{Versicolor},i} \\right) = \n",
    "\\begin{pmatrix} \n",
    "\\frac{5.1 + 4.9 + 5.0 + 7.0 + 6.4 + 6.9}{6} \\\\ \n",
    "\\frac{3.5 + 3.0 + 3.4 + 3.2 + 3.2 + 3.1}{6} \n",
    "\\end{pmatrix} = \n",
    "\\begin{pmatrix} \n",
    "5.883 \\\\ \n",
    "3.233 \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### クラス間ばらつき行列の計算\n",
    "\n",
    "クラス間ばらつき行列は、クラスごとの平均ベクトルが全体の平均からどれだけ離れているかを示します。\n",
    "\n",
    "$$\n",
    "\\mathbf{S}_B = 3 (\\mathbf{\\mu}_{\\text{Setosa}} - \\mathbf{\\mu})(\\mathbf{\\mu}_{\\text{Setosa}} - \\mathbf{\\mu})^T + 3 (\\mathbf{\\mu}_{\\text{Versicolor}} - \\mathbf{\\mu})(\\mathbf{\\mu}_{\\text{Versicolor}} - \\mathbf{\\mu})^T\n",
    "$$\n",
    "\n",
    "計算してみます：\n",
    "$$\n",
    "(\\mathbf{\\mu}_{\\text{Setosa}} - \\mathbf{\\mu}) = \n",
    "\\begin{pmatrix} \n",
    "5.0 \\\\ \n",
    "3.3 \n",
    "\\end{pmatrix} - \n",
    "\\begin{pmatrix} \n",
    "5.883 \\\\ \n",
    "3.233 \n",
    "\\end{pmatrix} = \n",
    "\\begin{pmatrix} \n",
    "-0.883 \\\\ \n",
    "0.067 \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{\\mu}_{\\text{Versicolor}} - \\mathbf{\\mu}) = \n",
    "\\begin{pmatrix} \n",
    "6.76 \\\\ \n",
    "3.17 \n",
    "\\end{pmatrix} - \n",
    "\\begin{pmatrix} \n",
    "5.883 \\\\ \n",
    "3.233 \n",
    "\\end{pmatrix} = \n",
    "\\begin{pmatrix} \n",
    "0.877 \\\\ \n",
    "-0.063 \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{\\mu}_{\\text{Setosa}} - \\mathbf{\\mu})(\\mathbf{\\mu}_{\\text{Setosa}} - \\mathbf{\\mu})^T = \n",
    "\\begin{pmatrix} \n",
    "-0.883 \\\\ \n",
    "0.067 \n",
    "\\end{pmatrix} \n",
    "\\begin{pmatrix} \n",
    "-0.883 & 0.067 \n",
    "\\end{pmatrix} = \n",
    "\\begin{pmatrix} \n",
    "0.779 & -0.059 \\\\ \n",
    "-0.059 & 0.004 \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{\\mu}_{\\text{Versicolor}} - \\mathbf{\\mu})(\\mathbf{\\mu}_{\\text{Versicolor}} - \\mathbf{\\mu})^T = \n",
    "\\begin{pmatrix} \n",
    "0.877 \\\\ \n",
    "-0.063 \n",
    "\\end{pmatrix} \n",
    "\\begin{pmatrix} \n",
    "0.877 & -0.063 \n",
    "\\end{pmatrix} = \n",
    "\\begin{pmatrix} \n",
    "0.769 & -0.055 \\\\ \n",
    "-0.055 & 0.004 \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "これらの行列を足し合わせます：\n",
    "$$\n",
    "\\mathbf{S}_B = 3 \n",
    "\\begin{pmatrix} \n",
    "0.779 & -0.059 \\\\ \n",
    "-0.059 & 0.004 \n",
    "\\end{pmatrix} + 3 \n",
    "\\begin{pmatrix} \n",
    "0.769 & -0.055 \\\\ \n",
    "-0.055 & 0.004 \n",
    "\\end{pmatrix} = 3 \n",
    "\\begin{pmatrix} \n",
    "1.548 & -0.114 \\\\ \n",
    "-0.114 & 0.008 \n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.88333333, 3.23333333])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_overall = np.mean(np.vstack((setosa, versicolor)), axis=0) # 普通のμで表現されている\n",
    "mu_overall\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.68166667, -0.35333333],\n",
       "       [-0.35333333,  0.02666667]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# クラス間ばらつき行列\n",
    "S_B_setosa = 3 * np.outer((mu_setosa - mu_overall), (mu_setosa - mu_overall))\n",
    "S_B_versicolor = 3 * np.outer((mu_versicolor - mu_overall), (mu_versicolor - mu_overall))\n",
    "\n",
    "S_B = S_B_setosa + S_B_versicolor\n",
    "S_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プロジェクションの計算\n",
    "\n",
    "次に、クラス間ばらつき行列 $\\mathbf{S}_B$ とクラス内ばらつき行列 $\\mathbf{S}_W$ を用いて、最適なプロジェクションベクトル $\\mathbf{w}$ を計算します。\n",
    "\n",
    "一般化固有値問題を解きます：\n",
    "$$\n",
    "\\mathbf{S}_B \\mathbf{w} = \\lambda \\mathbf{S}_W \\mathbf{w}\n",
    "$$\n",
    "\n",
    "これにより、最適なプロジェクションベクトル $\\mathbf{w}$ を得ます。計算の具体的な解法には、線形代数の技法（固有値問題の解法）が必要ですが、ここでは数学的に最適なベクトル $\\mathbf{w}$ を得るために必要なステップを示しました。\n",
    "\n",
    "### まとめ\n",
    "\n",
    "この例では、具体的な数値を用いてクラス間ばらつき行列、クラス内ばらつき行列、そしてプロジェクションの計算を行いました。これにより、LDAの計算の流れと各ステップの意味が明確になることを期待します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.94093284, -0.33859326])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals, eigvecs = np.linalg.eig(np.linalg.inv(S_W).dot(S_B))\n",
    "eigvecs = eigvecs[:, np.argsort(eigvals)[::-1]]  # 固有値の大きい順にソート\n",
    "\n",
    "# 最適なプロジェクションベクトル\n",
    "w = eigvecs[:, 0]\n",
    "w\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
