{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基本的な概念\n",
    "\n",
    "線形判別分析は、データをクラスに分類するための手法です。複数のクラスが存在するデータセットがあり、新しいデータがどのクラスに属するかを予測するために使われます。\n",
    "\n",
    "### 行列を使った説明\n",
    "\n",
    "1. **データセットの準備**:\n",
    "   各データ点は特徴量ベクトルで表されます。例えば、特徴量が2つ（$x_1$, $x_2$）の場合、データ点は $(x_1, x_2)$ という形になります。\n",
    "\n",
    "2. **クラスごとの平均ベクトル**:\n",
    "   各クラスに対して、そのクラスに属するデータ点の平均ベクトルを計算します。クラス $k$ の平均ベクトル $\\mathbf{\\mu}_k$ は次のように計算されます：\n",
    "   $$\n",
    "   \\mathbf{\\mu}_k = \\frac{1}{N_k} \\sum_{i \\in C_k} \\mathbf{x}_i\n",
    "   $$\n",
    "   ここで、$N_k$ はクラス $k$ のデータ点の数、$C_k$ はクラス $k$ に属するデータ点の集合です。\n",
    "\n",
    "3. **クラス内散布行列**:\n",
    "   各クラス内でのデータのばらつきを表す行列です。クラス $k$ のクラス内散布行列 $\\mathbf{S}_k$ は次のように計算されます：\n",
    "   $$\n",
    "   \\mathbf{S}_k = \\sum_{i \\in C_k} (\\mathbf{x}_i - \\mathbf{\\mu}_k)(\\mathbf{x}_i - \\mathbf{\\mu}_k)^T\n",
    "   $$\n",
    "\n",
    "4. **全クラスのクラス内散布行列**:\n",
    "   全クラスのクラス内散布行列を合計して、全クラスのクラス内散布行列 $\\mathbf{S}_W$ を求めます：\n",
    "   $$\n",
    "   \\mathbf{S}_W = \\sum_{k=1}^{K} \\mathbf{S}_k\n",
    "   $$\n",
    "\n",
    "5. **クラス間散布行列**:\n",
    "   各クラスの平均ベクトルと全体の平均ベクトルとの差を考慮して、クラス間のばらつきを表す行列です。全体の平均ベクトル $\\mathbf{\\mu}$ は次のように計算されます：\n",
    "   $$\n",
    "   \\mathbf{\\mu} = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbf{x}_i\n",
    "   $$\n",
    "   クラス $k$ のクラス間散布行列 $\\mathbf{S}_B$ は次のように計算されます：\n",
    "   $$\n",
    "   \\mathbf{S}_B = \\sum_{k=1}^{K} N_k (\\mathbf{\\mu}_k - \\mathbf{\\mu})(\\mathbf{\\mu}_k - \\mathbf{\\mu})^T\n",
    "   $$\n",
    "\n",
    "6. **最適な判別基準の計算**:\n",
    "   LDA の目的は、クラス間のばらつきを最大化しながら、クラス内のばらつきを最小化するような線形変換を見つけることです。これを行うために、次の最適化問題を解きます：\n",
    "   $$\n",
    "   \\mathbf{w} = \\arg\\max_{\\mathbf{w}} \\frac{\\mathbf{w}^T \\mathbf{S}_B \\mathbf{w}}{\\mathbf{w}^T \\mathbf{S}_W \\mathbf{w}}\n",
    "   $$\n",
    "   この問題を解くことで、判別基準となるベクトル $\\mathbf{w}$ を得ます。このベクトルを使って、新しいデータを分類します。\n",
    "\n",
    "### 結論\n",
    "\n",
    "線形判別分析は、行列やベクトルの操作を使ってデータを分類する手法です。クラスごとの平均ベクトルや散布行列を計算し、クラス間のばらつきを最大化し、クラス内のばらつきを最小化するような線形変換を見つけます。行列の基本操作を理解することで、LDAの背後にある数学的な考え方がわかりやすくなります。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実際の例を挙げながら説明してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "わかりました。それでは、実際の花のデータを使って、線形判別分析のステップを具体的に説明します。ここでは、アイリスデータセット（有名な花のデータセット）を使います。このデータセットには、3種類のアイリスの花（Setosa、Versicolor、Virginica）がありますが、ここではSetosaとVersicolorの2種類に絞って説明します。\n",
    "\n",
    "### ステップ1: データの準備\n",
    "\n",
    "データセットには、各花のがく片（sepal）の長さと幅、花弁（petal）の長さと幅が含まれています。ここでは、がく片の長さと幅の2つの特徴量を使います。\n",
    "\n",
    "| 花の種類  | がく片の長さ (cm) | がく片の幅 (cm) |\n",
    "|-------|-------------|-------------|\n",
    "| Setosa | 5.1         | 3.5         |\n",
    "| Setosa | 4.9         | 3.0         |\n",
    "| ...   | ...         | ...         |\n",
    "| Versicolor | 7.0     | 3.2         |\n",
    "| Versicolor | 6.4     | 3.2         |\n",
    "| ...   | ...         | ...         |\n",
    "\n",
    "### ステップ2: 平均ベクトルの計算\n",
    "\n",
    "それぞれのクラス（花の種類）について、平均ベクトルを計算します。\n",
    "\n",
    "#### Setosaの平均ベクトル\n",
    "$$\n",
    "\\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} \\mu_{Setosa, sepal\\_length} \\\\ \\mu_{Setosa, sepal\\_width} \\end{pmatrix} = \\begin{pmatrix} 5.0 \\\\ 3.4 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "#### Versicolorの平均ベクトル\n",
    "$$\n",
    "\\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} \\mu_{Versicolor, sepal\\_length} \\\\ \\mu_{Versicolor, sepal\\_width} \\end{pmatrix} = \\begin{pmatrix} 5.9 \\\\ 2.8 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### ステップ3: クラス内ばらつき行列の計算\n",
    "\n",
    "各クラス内のデータのばらつきを行列で表します。\n",
    "\n",
    "#### Setosaのクラス内ばらつき行列\n",
    "$$\n",
    "\\mathbf{S}_{\\text{Setosa}} = \\sum_{i=1}^{N_{Setosa}} (\\mathbf{x}_i - \\mathbf{\\mu}_{\\text{Setosa}})(\\mathbf{x}_i - \\mathbf{\\mu}_{\\text{Setosa}})^T\n",
    "$$\n",
    "\n",
    "#### Versicolorのクラス内ばらつき行列\n",
    "$$\n",
    "\\mathbf{S}_{\\text{Versicolor}} = \\sum_{i=1}^{N_{Versicolor}} (\\mathbf{x}_i - \\mathbf{\\mu}_{\\text{Versicolor}})(\\mathbf{x}_i - \\mathbf{\\mu}_{\\text{Versicolor}})^T\n",
    "$$\n",
    "\n",
    "### ステップ4: 全体のクラス内ばらつき行列の計算\n",
    "\n",
    "全体のクラス内ばらつき行列は、それぞれのクラス内ばらつき行列の合計です。\n",
    "$$\n",
    "\\mathbf{S}_W = \\mathbf{S}_{\\text{Setosa}} + \\mathbf{S}_{\\text{Versicolor}}\n",
    "$$\n",
    "\n",
    "### ステップ5: クラス間ばらつき行列の計算\n",
    "\n",
    "全体の平均ベクトルを計算し、クラス間のばらつきを行列で表します。\n",
    "\n",
    "#### 全体の平均ベクトル\n",
    "$$\n",
    "\\mathbf{\\mu} = \\frac{1}{N_{Setosa} + N_{Versicolor}} \\left( \\sum_{i=1}^{N_{Setosa}} \\mathbf{x}_i + \\sum_{i=1}^{N_{Versicolor}} \\mathbf{x}_i \\right)\n",
    "$$\n",
    "\n",
    "#### クラス間ばらつき行列\n",
    "$$\n",
    "\\mathbf{S}_B = N_{Setosa} (\\mathbf{\\mu}_{\\text{Setosa}} - \\mathbf{\\mu})(\\mathbf{\\mu}_{\\text{Setosa}} - \\mathbf{\\mu})^T + N_{Versicolor} (\\mathbf{\\mu}_{\\text{Versicolor}} - \\mathbf{\\mu})(\\mathbf{\\mu}_{\\text{Versicolor}} - \\mathbf{\\mu})^T\n",
    "$$\n",
    "\n",
    "### ステップ6: 最適な判別基準の計算\n",
    "\n",
    "LDAの目的は、次の最適化問題を解くことです：\n",
    "$$\n",
    "\\mathbf{w} = \\arg\\max_{\\mathbf{w}} \\frac{\\mathbf{w}^T \\mathbf{S}_B \\mathbf{w}}{\\mathbf{w}^T \\mathbf{S}_W \\mathbf{w}}\n",
    "$$\n",
    "\n",
    "この問題を解くことで、判別基準となるベクトル $\\mathbf{w}$ を得ます。このベクトルを使って、新しいデータを分類します。\n",
    "\n",
    "### まとめ\n",
    "\n",
    "具体的な花のデータを使って、LDAの各ステップを説明しました。行列の計算を通じて、データのばらつきや平均を求め、最適な分類線を見つけることで、新しいデータの分類が可能になります。これで、LDAの背後にある数学的な考え方と実際の計算の結びつきがわかりやすくなったと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ばらつき行列について理解できません。数字を出しながら説明してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ばらつき行列（散布行列）について、具体的な数値を使って説明します。アイリスデータセットのSetosaとVersicolorのデータを簡単な例として用います。\n",
    "\n",
    "### サンプルデータ\n",
    "SetosaとVersicolorの花のデータが以下のように与えられているとします。\n",
    "\n",
    "#### Setosa\n",
    "| がく片の長さ (cm) | がく片の幅 (cm) |\n",
    "|-------------|-------------|\n",
    "| 5.1         | 3.5         |\n",
    "| 4.9         | 3.0         |\n",
    "| 5.0         | 3.4         |\n",
    "\n",
    "#### Versicolor\n",
    "| がく片の長さ (cm) | がく片の幅 (cm) |\n",
    "|-------------|-------------|\n",
    "| 7.0         | 3.2         |\n",
    "| 6.4         | 3.2         |\n",
    "| 6.9         | 3.1         |\n",
    "\n",
    "### 平均ベクトルの計算\n",
    "\n",
    "まず、各クラスの平均ベクトルを計算します。\n",
    "\n",
    "#### Setosaの平均ベクトル\n",
    "$$\n",
    "\\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} \\mu_{1x} \\\\ \\mu_{1y} \\end{pmatrix} = \\begin{pmatrix} \\frac{5.1 + 4.9 + 5.0}{3} \\\\ \\frac{3.5 + 3.0 + 3.4}{3} \\end{pmatrix} = \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "#### Versicolorの平均ベクトル\n",
    "$$\n",
    "\\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} \\mu_{2x} \\\\ \\mu_{2y} \\end{pmatrix} = \\begin{pmatrix} \\frac{7.0 + 6.4 + 6.9}{3} \\\\ \\frac{3.2 + 3.2 + 3.1}{3} \\end{pmatrix} = \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### クラス内ばらつき行列の計算\n",
    "\n",
    "次に、各クラスのクラス内ばらつき行列を計算します。\n",
    "\n",
    "#### Setosaのクラス内ばらつき行列\n",
    "Setosaのデータ点の偏差ベクトルを求め、その外積をとります。\n",
    "\n",
    "1. データ点 (5.1, 3.5)\n",
    "$$\n",
    "\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} 5.1 \\\\ 3.5 \\end{pmatrix} - \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix} = \\begin{pmatrix} 0.1 \\\\ 0.2 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Setosa}})(\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Setosa}})^T = \\begin{pmatrix} 0.1 \\\\ 0.2 \\end{pmatrix} \\begin{pmatrix} 0.1 & 0.2 \\end{pmatrix} = \\begin{pmatrix} 0.01 & 0.02 \\\\ 0.02 & 0.04 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "2. データ点 (4.9, 3.0)\n",
    "$$\n",
    "\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} 4.9 \\\\ 3.0 \\end{pmatrix} - \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix} = \\begin{pmatrix} -0.1 \\\\ -0.3 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Setosa}})(\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Setosa}})^T = \\begin{pmatrix} -0.1 \\\\ -0.3 \\end{pmatrix} \\begin{pmatrix} -0.1 & -0.3 \\end{pmatrix} = \\begin{pmatrix} 0.01 & 0.03 \\\\ 0.03 & 0.09 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "3. データ点 (5.0, 3.4)\n",
    "$$\n",
    "\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} 5.0 \\\\ 3.4 \\end{pmatrix} - \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0.1 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Setosa}})(\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Setosa}})^T = \\begin{pmatrix} 0 \\\\ 0.1 \\end{pmatrix} \\begin{pmatrix} 0 & 0.1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0.01 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Setosaのクラス内ばらつき行列 $\\mathbf{S}_{\\text{Setosa}}$ はこれらの和です：\n",
    "$$\n",
    "\\mathbf{S}_{\\text{Setosa}} = \\begin{pmatrix} 0.01 & 0.02 \\\\ 0.02 & 0.04 \\end{pmatrix} + \\begin{pmatrix} 0.01 & 0.03 \\\\ 0.03 & 0.09 \\end{pmatrix} + \\begin{pmatrix} 0 & 0 \\\\ 0 & 0.01 \\end{pmatrix} = \\begin{pmatrix} 0.02 & 0.05 \\\\ 0.05 & 0.14 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "#### Versicolorのクラス内ばらつき行列\n",
    "同様にしてVersicolorのクラス内ばらつき行列を計算します。\n",
    "\n",
    "1. データ点 (7.0, 3.2)\n",
    "$$\n",
    "\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} 7.0 \\\\ 3.2 \\end{pmatrix} - \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix} = \\begin{pmatrix} 0.24 \\\\ 0.03 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Versicolor}})(\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Versicolor}})^T = \\begin{pmatrix} 0.24 \\\\ 0.03 \\end{pmatrix} \\begin{pmatrix} 0.24 & 0.03 \\end{pmatrix} = \\begin{pmatrix} 0.0576 & 0.0072 \\\\ 0.0072 & 0.0009 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "2. データ点 (6.4, 3.2)\n",
    "$$\n",
    "\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} 6.4 \\\\ 3.2 \\end{pmatrix} - \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix} = \\begin{pmatrix} -0.36 \\\\ 0.03 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Versicolor}})(\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Versicolor}})^T = \\begin{pmatrix} -0.36 \\\\ 0.03 \\end{pmatrix} \\begin{pmatrix} -0.36 & 0.03 \\end{pmatrix} = \\begin{pmatrix} 0.1296 & -0.0108 \\\\ -0.0108 & 0.0009 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "3. データ点 (6.9, 3.1)\n",
    "$$\n",
    "\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} 6.9 \\\\ 3.1 \\end{pmatrix} - \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix} = \\begin{pmatrix} 0.14 \\\\ -0.07 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Versicolor}})(\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Versicolor}})^T = \\begin{pmatrix} 0.14 \\\\ -0.07 \\end{pmatrix} \\begin{pmatrix} 0.14 & -0.07 \\end{pmatrix} = \\begin{pmatrix} 0.0196 & -0.0098 \\\\ -0.0098 & 0.0049 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Versicolorのクラス内ばらつき行列 $\\mathbf{S}_{\\text{Versicolor}}$ はこれらの和です：\n",
    "$$\n",
    "\\mathbf{S}_{\\text{Versicolor}} = \\begin{pmatrix} 0.0576 & 0.0072 \\\\ 0.0072 & 0.0009 \\end{pmatrix} + \\begin{pmatrix} 0.1296 & -0.0108 \\\\ -0.0108 & 0.0009 \\end{pmatrix} + \\begin{pmatrix} 0.0196 & -0.0098 \\\\ -0.0098 & 0.0049 \\end{pmatrix} = \\begin{pmatrix} 0.2068 & -0.0134 \\\\ -0.0134 & 0.0067 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### クラス内ばらつき行列の合計\n",
    "全体のクラス内ばらつき行列 $\\mathbf{S}_W$ は、SetosaとVersicolorのクラス内ばらつき行列の合計です：\n",
    "$$\n",
    "\\mathbf{S}_W = \\mathbf{S}_{\\text{Setosa}} + \\mathbf{S}_{\\text{Versicolor}} = \\begin{pmatrix} 0.02 & 0.05 \\\\ 0.05 & 0.14 \\end{pmatrix} + \\begin{pmatrix} 0.2068 & -0.0134 \\\\ -0.0134 & 0.0067 \\end{pmatrix} = \\begin{pmatrix} 0.2268 & 0.0366 \\\\ 0.0366 & 0.1467 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "このように、各クラスのデータ点のばらつきを計算し、行列として表現することで、データのばらつきを具体的に理解することができます。これがLDAにおけるばらつき行列の計算方法です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "了解しました。このステップは線形判別分析（LDA）の最も重要な部分で、データを最もよく分けるための最適な線を見つける部分です。以下に、この部分について詳しく説明します。\n",
    "\n",
    "### 目的\n",
    "\n",
    "LDAの目的は、データを異なるクラスにうまく分類するための最適な線（または平面）を見つけることです。この線は、クラス間のばらつきを最大化し、クラス内のばらつきを最小化するように選ばれます。\n",
    "\n",
    "### 数式の意味\n",
    "\n",
    "最適な線を見つけるために、以下の最適化問題を解きます：\n",
    "$$\n",
    "\\mathbf{w} = \\arg\\max_{\\mathbf{w}} \\frac{\\mathbf{w}^T \\mathbf{S}_B \\mathbf{w}}{\\mathbf{w}^T \\mathbf{S}_W \\mathbf{w}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数式の意味\n",
    "\n",
    "1. **$\\mathbf{w}$**:\n",
    "   - これは、データをプロジェクションするためのベクトルです。LDAでは、このベクトルを見つけることが目的です。\n",
    "\n",
    "2. **$\\mathbf{S}_B$**:\n",
    "   - クラス間ばらつき行列です。これは、各クラスの平均が全体の平均からどれだけ離れているかを示します。\n",
    "\n",
    "3. **$\\mathbf{S}_W$**:\n",
    "   - クラス内ばらつき行列です。これは、各クラス内のデータのばらつきを示します。\n",
    "\n",
    "4. **$\\mathbf{w}^T \\mathbf{S}_B \\mathbf{w}$**:\n",
    "   - これは、ベクトル $\\mathbf{w}$ によってプロジェクションされた後のクラス間のばらつきを表します。\n",
    "\n",
    "5. **$\\mathbf{w}^T \\mathbf{S}_W \\mathbf{w}$**:\n",
    "   - これは、ベクトル $\\mathbf{w}$ によってプロジェクションされた後のクラス内のばらつきを表します。\n",
    "\n",
    "### 最適化問題の意図\n",
    "\n",
    "最適化問題の意図は、クラス間のばらつきを最大化し、同時にクラス内のばらつきを最小化することです。数式で言うと、分子 $\\mathbf{w}^T \\mathbf{S}_B \\mathbf{w}$ を最大化し、分母 $\\mathbf{w}^T \\mathbf{S}_W \\mathbf{w}$ を最小化することです。これにより、異なるクラスがより明確に分離されるようになります。\n",
    "\n",
    "### 解法\n",
    "\n",
    "この最適化問題は、一般的に次の手順で解かれます。\n",
    "\n",
    "1. **一般化固有値問題の解法**:\n",
    "   - 次の一般化固有値問題を解きます：\n",
    "     $$\n",
    "     \\mathbf{S}_B \\mathbf{w} = \\lambda \\mathbf{S}_W \\mathbf{w}\n",
    "     $$\n",
    "   - ここで、$\\lambda$ は固有値、$\\mathbf{w}$ は対応する固有ベクトルです。\n",
    "\n",
    "2. **固有ベクトルの選択**:\n",
    "   - 固有値が最大となる固有ベクトル $\\mathbf{w}$ を選びます。このベクトルが最適なプロジェクション方向となります。\n",
    "\n",
    "### 結果の利用\n",
    "\n",
    "得られたベクトル $\\mathbf{w}$ を使って、データを新しい空間にプロジェクションします。具体的には、新しいデータ点 $\\mathbf{x}$ を $\\mathbf{w}$ に沿ってプロジェクションすることで、スカラー値 $\\mathbf{w}^T \\mathbf{x}$ を得ます。このスカラー値を使って、データがどのクラスに属するかを判断します。\n",
    "\n",
    "### まとめ\n",
    "\n",
    "この最適化問題を解くことで、データを異なるクラスにうまく分けるための最適な線（またはベクトル）$\\mathbf{w}$ を見つけます。このベクトルを使って、新しいデータを分類することができます。クラス間のばらつきを最大化し、クラス内のばらつきを最小化することで、LDAは分類性能を向上させます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# プロジェクションとは何ですか？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "プロジェクション（射影）とは、ある高次元空間の点をより低次元の空間に写し取る操作のことです。直感的に言うと、プロジェクションはデータの次元を減らすための方法です。\n",
    "\n",
    "### 具体例で説明\n",
    "\n",
    "例えば、3次元空間の点を2次元の平面にプロジェクトすることを考えてみましょう。\n",
    "\n",
    "#### 3次元の点\n",
    "3次元空間には $(x, y, z)$ という座標があります。\n",
    "\n",
    "#### 2次元へのプロジェクション\n",
    "この点を $z$ 軸に垂直な平面（例えば $xy$ 平面）にプロジェクトすると、$z$ の情報は失われ、点の座標は $(x, y)$ になります。これは、3次元の点を2次元に「写し取った」ことを意味します。\n",
    "\n",
    "### 線形判別分析（LDA）でのプロジェクション\n",
    "\n",
    "LDAにおいて、プロジェクションは次のように行われます：\n",
    "\n",
    "1. **高次元のデータ**：\n",
    "   元のデータは多次元（例えば、2次元、3次元、またはそれ以上）です。\n",
    "\n",
    "2. **ベクトル $\\mathbf{w}$ の決定**：\n",
    "   最適なプロジェクション方向（ベクトル $\\mathbf{w}$）を見つけます。このベクトルは、クラス間のばらつきを最大化し、クラス内のばらつきを最小化する方向です。\n",
    "\n",
    "3. **データのプロジェクション**：\n",
    "   各データ点 $\\mathbf{x}$ をベクトル $\\mathbf{w}$ にプロジェクトします。これは、スカラー値 $\\mathbf{w}^T \\mathbf{x}$ を計算することで行われます。このスカラー値は、元の高次元空間のデータ点を1次元の空間に写し取った値です。\n",
    "\n",
    "具体的には、データ点 $\\mathbf{x}$ をベクトル $\\mathbf{w}$ にプロジェクトすることで、新しい1次元の座標（スカラー値）を得ます：\n",
    "$$\n",
    "y = \\mathbf{w}^T \\mathbf{x}\n",
    "$$\n",
    "\n",
    "この結果、元の高次元データは1次元の空間に縮約されます。この1次元空間での値を使って、データのクラスを判別します。\n",
    "\n",
    "### まとめ\n",
    "\n",
    "プロジェクションとは、データを高次元空間から低次元空間に写し取る操作です。LDAでは、プロジェクションを使ってデータを低次元空間に縮約し、データのクラス間の分離を最大化することを目指します。これにより、データの次元が減少し、視覚化や解析が容易になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "5.1 & 3.5 \\\\\n",
    "4.9 & 3.0 \\\\\n",
    "5.0 & 3.4\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "7.0 & 3.2 \\\\\n",
    "6.4 & 3.2 \\\\\n",
    "6.9 & 3.1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "各クラスの平均ベクトルを計算します。\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} \\frac{5.1 + 4.9 + 5.0}{3} \\\\ \\frac{3.5 + 3.0 + 3.4}{3} \\end{pmatrix} = \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} \\frac{7.0 + 6.4 + 6.9}{3} \\\\ \\frac{3.2 + 3.2 + 3.1}{3} \\end{pmatrix} = \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "各クラス内のデータのばらつきを計算します。\n",
    "\n",
    "\n",
    "\n",
    "1. データ点 (5.1, 3.5)\n",
    "$$\n",
    "\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} 5.1 \\\\ 3.5 \\end{pmatrix} - \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix} = \\begin{pmatrix} 0.1 \\\\ 0.2 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Setosa}})(\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Setosa}})^T = \\begin{pmatrix} 0.1 \\\\ 0.2 \\end{pmatrix} \\begin{pmatrix} 0.1 & 0.2 \\end{pmatrix} = \\begin{pmatrix} 0.01 & 0.02 \\\\ 0.02 & 0.04 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "2. データ点 (4.9, 3.0)\n",
    "$$\n",
    "\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} 4.9 \\\\ 3.0 \\end{pmatrix} - \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix} = \\begin{pmatrix} -0.1 \\\\ -0.3 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Setosa}})(\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Setosa}})^T = \\begin{pmatrix} -0.1 \\\\ -0.3 \\end{pmatrix} \\begin{pmatrix} -0.1 & -0.3 \\end{pmatrix} = \\begin{pmatrix} 0.01 & 0.03 \\\\ 0.03 & 0.09 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "3. データ点 (5.0, 3.4)\n",
    "$$\n",
    "\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} 5.0 \\\\ 3.4 \\end{pmatrix} - \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0.1 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Setosa}})(\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Setosa}})^T = \\begin{pmatrix} 0 \\\\ 0.1 \\end{pmatrix} \\begin{pmatrix} 0 & 0.1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0.01 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Setosaのクラス内ばらつき行列 $\\mathbf{S}_{\\text{Setosa}}$ はこれらの和です：\n",
    "$$\n",
    "\\mathbf{S}_{\\text{Setosa}} = \\begin{pmatrix} 0.01 & 0.02 \\\\ 0.02 & 0.04 \\end{pmatrix} + \\begin{pmatrix} 0.01 & 0.03 \\\\ 0.03 & 0.09 \\end{pmatrix} + \\begin{pmatrix} 0 & 0 \\\\ 0 & 0.01 \\end{pmatrix} = \\begin{pmatrix} 0.02 & 0.05 \\\\ 0.05 & 0.14 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "1. データ点 (7.0, 3.2)\n",
    "$$\n",
    "\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} 7.0 \\\\ 3.2 \\end{pmatrix} - \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix} = \\begin{pmatrix} 0.24 \\\\ 0.03 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Versicolor}})(\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Versicolor}})^T = \\begin{pmatrix} 0.24 \\\\ 0.03 \\end{pmatrix} \\begin{pmatrix} 0.24 & 0.03 \\end{pmatrix} = \\begin{pmatrix} 0.0576 & 0.0072 \\\\ 0.0072 & 0.0009 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "2. データ点 (6.4, 3.2)\n",
    "$$\n",
    "\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} 6.4 \\\\ 3.2 \\end{pmatrix} - \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix} = \\begin{pmatrix} -0.36 \\\\ 0.03 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Versicolor}})(\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Versicolor}})^T = \\begin{pmatrix} -0.36 \\\\ 0.03 \\end{pmatrix} \\begin{pmatrix} -0.36 & 0.03 \\end{pmatrix} = \\begin{pmatrix} 0.1296 & -0.0108 \\\\ -0.0108 & 0.0009 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "3. データ点 (6.9, 3.1)\n",
    "$$\n",
    "\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} 6.9 \\\\ 3.1 \\end{pmatrix} - \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix} = \\begin{pmatrix} 0.14 \\\\ -0.07 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Versicolor}})(\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Versicolor}})^T = \\begin{pmatrix} 0.14 \\\\ -0.07 \\end{pmatrix} \\begin{pmatrix} 0.14 & -0.07 \\end{pmatrix} = \\begin{pmatrix} 0.0196 & -0.0098 \\\\ -0.0098 & 0.0049 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Versicolorのクラス内ばらつき行列 $\\mathbf{S}_{\\text{Versicolor}}$ はこれらの和です：\n",
    "$$\n",
    "\\mathbf{S}_{\\text{Versicolor}} = \\begin{pmatrix} 0.0576 & 0.0072 \\\\ 0.0072 & 0.0009 \\end{pmatrix} + \\begin{pmatrix} 0.1296 & -0.0108 \\\\ -0.0108 & 0.0009 \\end{pmatrix} + \\begin{pmatrix} 0.0196 & -0.0098 \\\\ -0.0098 & 0.0049 \\end{pmatrix} = \\begin{pmatrix} 0.2068 & -0.0134 \\\\ -0.0134 & 0.0067 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### クラス内ばらつき行列の合計\n",
    "\n",
    "全体のクラス内ばらつき行列 $\\mathbf{S}_W$ は、SetosaとVersicolorのクラス内ばらつき行列の合計です：\n",
    "$$\n",
    "\\mathbf{S}_W = \\mathbf{S}_{\\text{Setosa}} + \\mathbf{S}_{\\text{Versicolor}} = \\begin{pmatrix} 0.02 & 0.05 \\\\ 0.05 & 0.14 \\end{pmatrix} + \\begin{pmatrix} 0.2068 & -0.0134 \\\\ -0.0134 & 0.0067 \\end{pmatrix} = \\begin{pmatrix} 0.2268 & 0.0366 \\\\ 0.0366 & 0.1467 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### クラス間ばらつき行列の計算\n",
    "\n",
    "クラス間ばらつき行列は、クラスごとの平均ベクトルが全体の平均からどれだけ離れているかを示します。\n",
    "\n",
    "#### 全体の平均ベクトル\n",
    "$$\n",
    "\\mathbf{\\mu} = \\frac{1}{6} \\left( \\sum_{i=1}^{3} \\mathbf{x}_{\\text{Setosa},i} + \\sum_{i=1}^{3} \\mathbf{x}_{\\text{Versicolor},i} \\right) = \\begin{pmatrix} \\frac{5.1 + 4.9 + 5.0 + 7.0 + 6.4 + 6.9}{6} \\\\ \\frac{3.5 + 3.0 + 3.4 + 3.2 + 3.2 + 3.1}{6} \\end{pmatrix} = \\begin{pmatrix} 5.883 \\\\ 3.233 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "#### クラス間ばらつき行列\n",
    "$$\n",
    "\\mathbf{S}_B = 3 (\\mathbf{\\mu}_{\\text{Setosa}} - \\mathbf{\\mu})(\\mathbf{\\mu}_{\\text{Setosa}} - \\mathbf{\\mu})^T + 3 (\\mathbf{\\mu}_{\\text{Versicolor}} - \\mathbf{\\mu})(\\mathbf{\\mu}_{\\text{Versicolor}} - \\mathbf{\\mu})^T\n",
    "$$\n",
    "\n",
    "計算してみます：\n",
    "$$\n",
    "(\\mathbf{\\mu}_{\\text{Setosa}} - \\mathbf{\\mu}) = \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix} - \\begin{pmatrix} 5.883 \\\\ 3.233 \\end{pmatrix} = \\begin{pmatrix} -0.883 \\\\ 0.067 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{\\mu}_{\\text{Versicolor}} - \\mathbf{\\mu}) = \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix} - \\begin{pmatrix} 5.883 \\\\ 3.233 \\end{pmatrix} = \\begin{pmatrix} 0.877 \\\\ -0.063 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{\\mu}_{\\text{Setosa}} - \\mathbf{\\mu})(\\mathbf{\\mu}_{\\text{Setosa}} - \\mathbf{\\mu})^T = \\begin{pmatrix} -0.883 \\\\ 0.067 \\end{pmatrix} \\begin{pmatrix} -0.883 & 0.067 \\end{pmatrix} = \\begin{pmatrix} 0.779 & -0.059 \\\\ -0.059 & 0.004 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{\\mu}_{\\text{Versicolor}} - \\mathbf{\\mu})(\\mathbf{\\mu}_{\\text{Versicolor}} - \\mathbf{\\mu})^T = \\begin{pmatrix} 0.877 \\\\ -0.063 \\end{pmatrix} \\begin{pmatrix} 0.877 & -0.063 \\end{pmatrix} = \\begin{pmatrix} 0.769 & -0.055 \\\\ -0.055 & 0.004 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "これらの行列を足し合わせます：\n",
    "$$\n",
    "\\mathbf{S}_B = 3 \\begin{pmatrix} 0.779 & -0.059 \\\\ -0.059 & 0.004 \\end{pmatrix} + 3 \\begin{pmatrix} 0.769 & -0.055 \\\\ -0.055 & 0.004 \\end{pmatrix} = 3 \\begin{pmatrix} 1.548 & -0.114 \\\\ -0.114 & 0.008 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### プロジェクションの計算\n",
    "\n",
    "次に、クラス間ばらつき行列 $\\mathbf{S}_B$ とクラス内ばらつき行列 $\\mathbf{S}_W$ を用いて、最適なプロジェクションベクトル $\\mathbf{w}$ を計算します。\n",
    "\n",
    "一般化固有値問題を解きます：\n",
    "$$\n",
    "\\mathbf{S}_B \\mathbf{w} = \\lambda \\mathbf{S}_W \\mathbf{w}\n",
    "$$\n",
    "\n",
    "これにより、最適なプロジェクションベクトル $\\mathbf{w}$ を得ます。計算の具体的な解法には、線形代数の技法（固有値問題の解法）が必要ですが、ここでは数学的に最適なベクトル $\\mathbf{w}$ を得るために必要なステップを示しました。\n",
    "\n",
    "### まとめ\n",
    "\n",
    "この例では、具体的な数値を用いてクラス間ばらつき行列、クラス内ばらつき行列、そしてプロジェクションの計算を行いました。これにより、LDAの計算の流れと各ステップの意味が明確になることを期待します。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 線形判別分析の具体例\n",
    "\n",
    "簡単のため、2つのクラス（Setosa と Versicolor）のデータを2つの特徴量（がく片の長さと幅）で表現します。\n",
    "\n",
    "## データセット\n",
    "\n",
    "### Setosa\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "5.1 & 3.5 \\\\\n",
    "4.9 & 3.0 \\\\\n",
    "5.0 & 3.4\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### Versicolor\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "7.0 & 3.2 \\\\\n",
    "6.4 & 3.2 \\\\\n",
    "6.9 & 3.1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "## 平均ベクトルの計算\n",
    "\n",
    "各クラスの平均ベクトルを計算します。\n",
    "\n",
    "### Setosaの平均ベクトル\n",
    "$$\n",
    "\\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} \\frac{5.1 + 4.9 + 5.0}{3} \\\\ \\frac{3.5 + 3.0 + 3.4}{3} \\end{pmatrix} = \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### Versicolorの平均ベクトル\n",
    "$$\n",
    "\\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} \\frac{7.0 + 6.4 + 6.9}{3} \\\\ \\frac{3.2 + 3.2 + 3.1}{3} \\end{pmatrix} = \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5. , 3.3]), array([6.76666667, 3.16666667]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# データセット\n",
    "setosa = np.array([[5.1, 3.5], [4.9, 3.0], [5.0, 3.4]])\n",
    "versicolor = np.array([[7.0, 3.2], [6.4, 3.2], [6.9, 3.1]])\n",
    "\n",
    "# 平均ベクトルの計算\n",
    "mu_setosa = np.mean(setosa, axis=0)\n",
    "mu_versicolor = np.mean(versicolor, axis=0)\n",
    "mu_setosa, mu_versicolor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## クラス内ばらつき行列の計算\n",
    "\n",
    "各クラス内のデータのばらつきを計算します。\n",
    "\n",
    "### Setosaのクラス内ばらつき行列\n",
    "\n",
    "1. データ点 (5.1, 3.5)\n",
    "$$\n",
    "\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} 5.1 \\\\ 3.5 \\end{pmatrix} - \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix} = \\begin{pmatrix} 0.1 \\\\ 0.2 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Setosa}})(\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Setosa}})^T = \\begin{pmatrix} 0.1 \\\\ 0.2 \\end{pmatrix} \\begin{pmatrix} 0.1 & 0.2 \\end{pmatrix} = \\begin{pmatrix} 0.01 & 0.02 \\\\ 0.02 & 0.04 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "2. データ点 (4.9, 3.0)\n",
    "$$\n",
    "\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} 4.9 \\\\ 3.0 \\end{pmatrix} - \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix} = \\begin{pmatrix} -0.1 \\\\ -0.3 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Setosa}})(\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Setosa}})^T = \\begin{pmatrix} -0.1 \\\\ -0.3 \\end{pmatrix} \\begin{pmatrix} -0.1 & -0.3 \\end{pmatrix} = \\begin{pmatrix} 0.01 & 0.03 \\\\ 0.03 & 0.09 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "3. データ点 (5.0, 3.4)\n",
    "$$\n",
    "\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Setosa}} = \\begin{pmatrix} 5.0 \\\\ 3.4 \\end{pmatrix} - \\begin{pmatrix} 5.0 \\\\ 3.3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0.1 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Setosa}})(\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Setosa}})^T = \\begin{pmatrix} 0 \\\\ 0.1 \\end{pmatrix} \\begin{pmatrix} 0 & 0.1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0.01 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Setosaのクラス内ばらつき行列 $\\mathbf{S}_{\\text{Setosa}}$ はこれらの和です：\n",
    "$$\n",
    "\\mathbf{S}_{\\text{Setosa}} = \\begin{pmatrix} 0.01 & 0.02 \\\\ 0.02 & 0.04 \\end{pmatrix} + \\begin{pmatrix} 0.01 & 0.03 \\\\ 0.03 & 0.09 \\end{pmatrix} + \\begin{pmatrix} 0 & 0 \\\\ 0 & 0.01 \\end{pmatrix} = \\begin{pmatrix} 0.02 & 0.05 \\\\ 0.05 & 0.14 \\end{pmatrix}\n",
    "$$\n",
    "### Versicolorのクラス内ばらつき行列\n",
    "\n",
    "1. データ点 (7.0, 3.2)\n",
    "$$\n",
    "\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} 7.0 \\\\ 3.2 \\end{pmatrix} - \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix} = \\begin{pmatrix} 0.24 \\\\ 0.03 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Versicolor}})(\\mathbf{x}_1 - \\mathbf{\\mu}_{\\text{Versicolor}})^T = \\begin{pmatrix} 0.24 \\\\ 0.03 \\end{pmatrix} \\begin{pmatrix} 0.24 & 0.03 \\end{pmatrix} = \\begin{pmatrix} 0.0576 & 0.0072 \\\\ 0.0072 & 0.0009 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "2. データ点 (6.4, 3.2)\n",
    "$$\n",
    "\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} 6.4 \\\\ 3.2 \\end{pmatrix} - \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix} = \\begin{pmatrix} -0.36 \\\\ 0.03 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Versicolor}})(\\mathbf{x}_2 - \\mathbf{\\mu}_{\\text{Versicolor}})^T = \\begin{pmatrix} -0.36 \\\\ 0.03 \\end{pmatrix} \\begin{pmatrix} -0.36 & 0.03 \\end{pmatrix} = \\begin{pmatrix} 0.1296 & -0.0108 \\\\ -0.0108 & 0.0009 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "3. データ点 (6.9, 3.1)\n",
    "$$\n",
    "\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Versicolor}} = \\begin{pmatrix} 6.9 \\\\ 3.1 \\end{pmatrix} - \\begin{pmatrix} 6.76 \\\\ 3.17 \\end{pmatrix} = \\begin{pmatrix} 0.14 \\\\ -0.07 \\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Versicolor}})(\\mathbf{x}_3 - \\mathbf{\\mu}_{\\text{Versicolor}})^T = \\begin{pmatrix} 0.14 \\\\ -0.07 \\end{pmatrix} \\begin{pmatrix} 0.14 & -0.07 \\end{pmatrix} = \\begin{pmatrix} 0.0196 & -0.0098 \\\\ -0.0098 & 0.0049 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Versicolorのクラス内ばらつき行列 $\\mathbf{S}_{\\text{Versicolor}}$ はこれらの和です：\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "0.0576 & 0.0072 \\\\\n",
    "0.0072 & 0.0009\n",
    "\\end{pmatrix} + \n",
    "\\begin{pmatrix}\n",
    "0.1296 & -0.0108 \\\\\n",
    "-0.0108 & 0.0009\n",
    "\\end{pmatrix} + \n",
    "\\begin{pmatrix}\n",
    "0.0196 & -0.0098 \\\\\n",
    "-0.0098 & 0.0049\n",
    "\\end{pmatrix} = \n",
    "\\begin{pmatrix}\n",
    "0.2068 & -0.0134 \\\\\n",
    "-0.0134 & 0.0067\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.02, 0.05],\n",
       "        [0.05, 0.14]]),\n",
       " array([[ 0.20666667, -0.01333333],\n",
       "        [-0.01333333,  0.00666667]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scatter_matrix(data, mean):\n",
    "    scatter = np.zeros((2, 2))\n",
    "    for x in data:\n",
    "        diff = (x - mean).reshape(2, 1)\n",
    "        scatter += diff @ diff.T\n",
    "    return scatter\n",
    "\n",
    "S_setosa = scatter_matrix(setosa, mu_setosa)\n",
    "S_versicolor = scatter_matrix(versicolor, mu_versicolor)\n",
    "S_setosa, S_versicolor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### クラス内ばらつき行列の合計\n",
    "\n",
    "全体のクラス内ばらつき行列 $\\mathbf{S}_W$ は、SetosaとVersicolorのクラス内ばらつき行列の合計です：\n",
    "$$\n",
    "\\mathbf{S}_W = \\mathbf{S}_{\\text{Setosa}} + \\mathbf{S}_{\\text{Versicolor}} = \n",
    "\\begin{pmatrix}\n",
    "0.02 & 0.05 \\\\\n",
    "0.05 & 0.14\n",
    "\\end{pmatrix} + \n",
    "\\begin{pmatrix}\n",
    "0.2068 & -0.0134 \\\\\n",
    "-0.0134 & 0.0067\n",
    "\\end{pmatrix} = \n",
    "\\begin{pmatrix}\n",
    "0.2268 & 0.0366 \\\\\n",
    "0.0366 & 0.1467\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22666667, 0.03666667],\n",
       "       [0.03666667, 0.14666667]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_W = S_setosa + S_versicolor\n",
    "S_W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全体の平均ベクトル\n",
    "\n",
    "$$\n",
    "\\mathbf{\\mu} = \\frac{1}{6} \\left( \\sum_{i=1}^{3} \\mathbf{x}_{\\text{Setosa},i} + \\sum_{i=1}^{3} \\mathbf{x}_{\\text{Versicolor},i} \\right) = \n",
    "\\begin{pmatrix} \n",
    "\\frac{5.1 + 4.9 + 5.0 + 7.0 + 6.4 + 6.9}{6} \\\\ \n",
    "\\frac{3.5 + 3.0 + 3.4 + 3.2 + 3.2 + 3.1}{6} \n",
    "\\end{pmatrix} = \n",
    "\\begin{pmatrix} \n",
    "5.883 \\\\ \n",
    "3.233 \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### クラス間ばらつき行列の計算\n",
    "\n",
    "クラス間ばらつき行列は、クラスごとの平均ベクトルが全体の平均からどれだけ離れているかを示します。\n",
    "\n",
    "$$\n",
    "\\mathbf{S}_B = 3 (\\mathbf{\\mu}_{\\text{Setosa}} - \\mathbf{\\mu})(\\mathbf{\\mu}_{\\text{Setosa}} - \\mathbf{\\mu})^T + 3 (\\mathbf{\\mu}_{\\text{Versicolor}} - \\mathbf{\\mu})(\\mathbf{\\mu}_{\\text{Versicolor}} - \\mathbf{\\mu})^T\n",
    "$$\n",
    "\n",
    "計算してみます：\n",
    "$$\n",
    "(\\mathbf{\\mu}_{\\text{Setosa}} - \\mathbf{\\mu}) = \n",
    "\\begin{pmatrix} \n",
    "5.0 \\\\ \n",
    "3.3 \n",
    "\\end{pmatrix} - \n",
    "\\begin{pmatrix} \n",
    "5.883 \\\\ \n",
    "3.233 \n",
    "\\end{pmatrix} = \n",
    "\\begin{pmatrix} \n",
    "-0.883 \\\\ \n",
    "0.067 \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{\\mu}_{\\text{Versicolor}} - \\mathbf{\\mu}) = \n",
    "\\begin{pmatrix} \n",
    "6.76 \\\\ \n",
    "3.17 \n",
    "\\end{pmatrix} - \n",
    "\\begin{pmatrix} \n",
    "5.883 \\\\ \n",
    "3.233 \n",
    "\\end{pmatrix} = \n",
    "\\begin{pmatrix} \n",
    "0.877 \\\\ \n",
    "-0.063 \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{\\mu}_{\\text{Setosa}} - \\mathbf{\\mu})(\\mathbf{\\mu}_{\\text{Setosa}} - \\mathbf{\\mu})^T = \n",
    "\\begin{pmatrix} \n",
    "-0.883 \\\\ \n",
    "0.067 \n",
    "\\end{pmatrix} \n",
    "\\begin{pmatrix} \n",
    "-0.883 & 0.067 \n",
    "\\end{pmatrix} = \n",
    "\\begin{pmatrix} \n",
    "0.779 & -0.059 \\\\ \n",
    "-0.059 & 0.004 \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{\\mu}_{\\text{Versicolor}} - \\mathbf{\\mu})(\\mathbf{\\mu}_{\\text{Versicolor}} - \\mathbf{\\mu})^T = \n",
    "\\begin{pmatrix} \n",
    "0.877 \\\\ \n",
    "-0.063 \n",
    "\\end{pmatrix} \n",
    "\\begin{pmatrix} \n",
    "0.877 & -0.063 \n",
    "\\end{pmatrix} = \n",
    "\\begin{pmatrix} \n",
    "0.769 & -0.055 \\\\ \n",
    "-0.055 & 0.004 \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "これらの行列を足し合わせます：\n",
    "$$\n",
    "\\mathbf{S}_B = 3 \n",
    "\\begin{pmatrix} \n",
    "0.779 & -0.059 \\\\ \n",
    "-0.059 & 0.004 \n",
    "\\end{pmatrix} + 3 \n",
    "\\begin{pmatrix} \n",
    "0.769 & -0.055 \\\\ \n",
    "-0.055 & 0.004 \n",
    "\\end{pmatrix} = 3 \n",
    "\\begin{pmatrix} \n",
    "1.548 & -0.114 \\\\ \n",
    "-0.114 & 0.008 \n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.88333333, 3.23333333])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_overall = np.mean(np.vstack((setosa, versicolor)), axis=0) # 普通のμで表現されている\n",
    "mu_overall\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.68166667, -0.35333333],\n",
       "       [-0.35333333,  0.02666667]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# クラス間ばらつき行列\n",
    "S_B_setosa = 3 * np.outer((mu_setosa - mu_overall), (mu_setosa - mu_overall))\n",
    "S_B_versicolor = 3 * np.outer((mu_versicolor - mu_overall), (mu_versicolor - mu_overall))\n",
    "\n",
    "S_B = S_B_setosa + S_B_versicolor\n",
    "S_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プロジェクションの計算\n",
    "\n",
    "次に、クラス間ばらつき行列 $\\mathbf{S}_B$ とクラス内ばらつき行列 $\\mathbf{S}_W$ を用いて、最適なプロジェクションベクトル $\\mathbf{w}$ を計算します。\n",
    "\n",
    "一般化固有値問題を解きます：\n",
    "$$\n",
    "\\mathbf{S}_B \\mathbf{w} = \\lambda \\mathbf{S}_W \\mathbf{w}\n",
    "$$\n",
    "\n",
    "これにより、最適なプロジェクションベクトル $\\mathbf{w}$ を得ます。計算の具体的な解法には、線形代数の技法（固有値問題の解法）が必要ですが、ここでは数学的に最適なベクトル $\\mathbf{w}$ を得るために必要なステップを示しました。\n",
    "\n",
    "### まとめ\n",
    "\n",
    "この例では、具体的な数値を用いてクラス間ばらつき行列、クラス内ばらつき行列、そしてプロジェクションの計算を行いました。これにより、LDAの計算の流れと各ステップの意味が明確になることを期待します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.94093284, -0.33859326])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals, eigvecs = np.linalg.eig(np.linalg.inv(S_W).dot(S_B))\n",
    "eigvecs = eigvecs[:, np.argsort(eigvals)[::-1]]  # 固有値の大きい順にソート\n",
    "\n",
    "# 最適なプロジェクションベクトル\n",
    "w = eigvecs[:, 0]\n",
    "w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.61368108, 3.59479114, 3.55344712]),\n",
       " array([5.50303145, 4.93847175, 5.44279749]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# プロジェクションベクトル\n",
    "w = eigvecs[:, 0]\n",
    "\n",
    "# 元のデータ点をプロジェクション\n",
    "setosa_proj = setosa.dot(w)\n",
    "versicolor_proj = versicolor.dot(w)\n",
    "\n",
    "# プロジェクションされたデータを確認\n",
    "setosa_proj, versicolor_proj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# プロジェクションされたデータをプロット\n",
    "plt.scatter(setosa_proj, np.zeros_like(setosa_proj), label='Setosa', alpha=0.5)\n",
    "plt.scatter(versicolor_proj, np.zeros_like(versicolor_proj), label='Versicolor', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.xlabel('Projected value')\n",
    "plt.title('LDA projection')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
